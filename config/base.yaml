# Common defaults for both binary and multiclass runs

data:
  preprocessed_dir: "data/preprocessed_log_mel_40_norm"
  val_split: 0.20
  test_split: 0.10

  # where raw audio lives
  raw_dir: "data/speech_commands_v0.02"

  # feature extraction settings
  features:
    type: log-mel              # mfcc | log-mel
    sample_rate: 16000         # sr
    n_features: 40             # 16-28 for mfcc, 40-80 for log-mel
    frame_length_s: 0.032      # seconds
    hop_length_s: 0.016        # seconds
    fixed_duration_s: 1.024    # seconds (pad/truncate)
    normalize: true            # normalize each sample audio file to [0, 1]

augmentation:
  enable: true               # turn off by setting false
  max_shift_ms: 100          # “up to 100 ms forward/backward shifts”
  noise_prob: 0.15           # 15% chance to add noise after the shift
  noise_std_factor: 0.05     # noise std = noise_std_factor * per-sample feature std
  seed: 0                    # optional; set null to get fully random every run

task:
  type: multiclass
  class_list: ["yes", "no", "up", "down", "left", "right", "on", "off", "stop", "go"]
  include_unknown: true
  include_background: false
  # Optional caps for training only
  unknown_max_ratio: null   # keep at most a portion of keyword samples
  unknown_max_count: null   # or an absolute cap (e.g., 5000); null to ignore

model:
  # Core
  hidden_channels: 26
  kernel_size: 3
  dropout: 0.2

  # Depth (number of residual TCN blocks, each with 2 layers (with equal exponential dilation)
  num_blocks: 4

  # Convolutional block options
  causal: true                      # causal padding + right-trim
  activation: relu                  # relu | gelu | prelu
  norm: batch                      # batch | group | layer | none
  groups_for_groupnorm: 8           # only used when norm=group
  use_weight_norm: false            # apply weight_norm to convs
  depthwise_separable: false        # use depthwise+pointwise convs
  pool: avg                         # avg | max (global pool over time)
  bias: false                       # include bias in conv layers

train:
  batch_size: 32
  num_epochs: 100
  learning_rate: 1.0e-4
  weight_decay: 1.0e-5
  device: auto               # "auto" | "cuda" | "cpu"

  # Early stopping configuration
  early_stopping:
    enabled: true
    patience: 10             # Stop if no improvement for 10 epochs
    metric: "val_loss"        # Monitor validation loss
    min_delta: 0.001         # Minimum change to qualify as improvement
    restore_best: true       # Load best weights before stopping

  # DataLoader performance knobs
  num_workers: 2             # >0 enables parallel loading (Windows-safe if main-guarded)
  pin_memory: true           # only helps when using CUDA
  persistent_workers: true   # keep workers alive across epochs (requires num_workers > 0)
  prefetch_factor: 2         # batches prefetched per worker

qat:
  # Quantization config for hardware constraints
  weight_quantization_method: linear    # "linear" | "log2" weight quantization
  weight_linear_quantization_bits: 3    # Weight linear quantization bits
  weight_log2_quantization_num_levels: 4  # Weight log2 quantization levels
  weight_min: -1.0                     # Minimum weight value
  weight_max: 1.0                      # Maximum weight value
  act_quantization_bits: 5             # Activation quantization bits (always linear)
  act_max: 1024.0                      # Max activation value (hardware constraint)
  batch_size: 32
  num_epochs: 5
  learning_rate: 1.0e-5
  device: auto                         # "auto" | "cuda" | "cpu"
  
  # DataLoader performance knobs
  num_workers: 2
  pin_memory: true
  persistent_workers: true
  prefetch_factor: 2

output:
  weights_dir: "checkpoints"
  plots_dir: "plots"
  tqdm: true




